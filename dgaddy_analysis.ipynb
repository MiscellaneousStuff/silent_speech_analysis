{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a02c22",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114fd488",
   "metadata": {},
   "source": [
    "## Setup Miniconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ff60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
    "MINICONDA_PREFIX=/usr/local\n",
    "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
    "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
    "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b760dc0",
   "metadata": {},
   "source": [
    "## Check Install Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab2bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which conda # should return /usr/local/bin/conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda --version # should return 4.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e87f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python # still returns /usr/local/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version # now returns Python 3.6.5 :: Anaconda, Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2641466",
   "metadata": {},
   "source": [
    "## Setup Environment using Miniconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "conda install --channel defaults conda python=3.6 --yes\n",
    "conda update --channel defaults --all --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dacb8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda --version # now returns 4.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd2abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version # now returns Python 3.6.10 :: Anaconda, Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "_ = (sys.path\n",
    "        .append(\"/usr/local/lib/python3.6/site-packages\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e42cdf",
   "metadata": {},
   "source": [
    "## Install Conda Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e67d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install --channel conda-forge featuretools --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6296dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install cudatoolkit=10.1 -y\n",
    "!conda install pytorch -c pytorch -y\n",
    "!conda install libsndfile=1.0.28 -c conda-forge -y\n",
    "!conda install ipykernel -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install absl-py librosa soundfile matplotlib scipy scikit-learn numba jiwer unidecode deepspeech==0.8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3dcc9",
   "metadata": {},
   "source": [
    "# Download and Check Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4bbd4",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb232022",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdrive = True\n",
    "if gdrive:\n",
    "    # Download from Google Drive, much faster than from source\n",
    "    # NOTE: Still getting this too work...\n",
    "    !EEG_DATA_ID=\"1GT_hZTCx0ihdjcPvQFgYltmNZU5iIxvj\" && \\\n",
    "    wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \"https://docs.google.com/uc?export=download&id=${EEG_DATA_ID}\" -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=${EEG_DATA_ID}\" -O emg_data.tar.gz && rm -rf /tmp/cookies.txt\n",
    "else:\n",
    "    # Download from source, slower but should be 100% reliable\n",
    "    !wget -O emg_data.tar.gz https://zenodo.org/record/4064409/files/emg_data.tar.gz?download=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3db6c5",
   "metadata": {},
   "source": [
    "## Phoneme Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7914f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O text_alignments.tar.gz https://github.com/dgaddy/silent_speech_alignments/raw/main/text_alignments.tar.gz\n",
    "!tar -xvf text_alignments.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d6aef",
   "metadata": {},
   "source": [
    "## Check EEG Dataset Size (Should be ~6.3GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a4a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh emg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125554dc",
   "metadata": {},
   "source": [
    "# Clone GDaddy/silent_speech Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf24a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/dgaddy/silent_speech/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a140d-0427-4ab7-9fe2-0f59b0d14692",
   "metadata": {},
   "source": [
    "# Closed Vocab Dataset\n",
    "This dataset is split into two modes:\n",
    "1. Voiced speech\n",
    "2. Silent speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e206f76-6b6d-49ac-b326-886db59f8b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required\n",
    "!pip install praat-textgrids\n",
    "\n",
    "# Use this to change dir (If not already in silent_speech repo dir)\n",
    "!pwd\n",
    "switch = False\n",
    "if switch:\n",
    "    %cd silent_speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a78cd-b0c6-427c-8d40-ec49d3a3c716",
   "metadata": {},
   "source": [
    "## Analyse Entire Dataset Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14defc20-6c19-481f-a026-d9dc8f912024",
   "metadata": {},
   "source": [
    "### Dataset Statistics\n",
    "According to the [Digital Voicing of Silent Speech](https://arxiv.org/pdf/2010.02960.pdf)\n",
    "paper, the closed vocabulary dataset should have the following chracteristics:\n",
    "- Parallel silent / vocalised Speech (Es, Ev, Av)\n",
    "  - 26 minutes silent / 30 minutes vocalised\n",
    "  - Single session (data was only recorded once)\n",
    "  - 500 utterances (500 different recordings)\n",
    "  - Average of 4 words per utterance\n",
    "  - 67 words in vocabulary (67 unique words were uttered in the entire dataset)\n",
    "  \n",
    "From the cells below, we can see the dataset matches the reported\n",
    "statistics within the paper, aside from the vocabulary.\n",
    "\n",
    "However, this is most likely due to how the vocabulary words\n",
    "are calculated by the authors. Hopefully this is easy to resolve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aad1f6-fe50-43d2-811e-e545a870c274",
   "metadata": {},
   "source": [
    "#### Extract Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733688e-7b10-47e8-8cb0-b175cb6a073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd silent_speech_analysis\n",
    "!pwd\n",
    "\n",
    "import os, json, glob\n",
    "\n",
    "# Silent and voiced directories\n",
    "emg_data_dir = \"emg_data/\"\n",
    "silent_dir = os.path.join(os.getcwd(), emg_data_dir, \"closed_vocab/silent/5-19_silent\")\n",
    "voiced_dir = os.path.join(os.getcwd(), emg_data_dir, \"closed_vocab/voiced/5-19\")\n",
    "\n",
    "# Calc unique words within a data directory\n",
    "def vocab_info(data_dir):\n",
    "    path = os.path.join(data_dir)\n",
    "    jsons = list(filter(lambda x: x.endswith(\".json\"), os.listdir(path)))\n",
    "    infos = []\n",
    "    for fname in jsons:\n",
    "        cur_fname = os.path.join(data_dir, fname)\n",
    "        with open(cur_fname) as f:\n",
    "            info = json.loads(f.read())\n",
    "            infos.append(info)\n",
    "    return infos\n",
    "\n",
    "# Get silent mode vocab\n",
    "silent_info = vocab_info(silent_dir)\n",
    "voiced_info = vocab_info(voiced_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a302bd3d-251e-431e-bd8e-dea74f65b1a4",
   "metadata": {},
   "source": [
    "#### Calculate Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6e934-6de5-47aa-965d-2ad51f585187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "reduce_year_vocab_size = False\n",
    "\n",
    "#silent_vocab = set()\n",
    "silent_vocab = list()\n",
    "for info in silent_info:\n",
    "    words = re.split(\":| \", info[\"text\"])\n",
    "    for w in words:\n",
    "        if len(w) == 4 and w.isnumeric() and reduce_year_vocab_size:\n",
    "            w1 = w[0:2]\n",
    "            w2 = w[2:4]\n",
    "            silent_vocab.append(w1)\n",
    "            silent_vocab.append(w2)\n",
    "            #silent_vocab.add(w1)\n",
    "            #silent_vocab.add(w2)\n",
    "        else:\n",
    "            # silent_vocab.add(w)\n",
    "            silent_vocab.append(w)\n",
    "silent_vocab.remove(\"\")\n",
    "\n",
    "voiced_vocab = set()\n",
    "for info in voiced_info:\n",
    "    words = re.split(\":| \", info[\"text\"])\n",
    "    for w in words:\n",
    "        if len(w) == 4 and w.isnumeric() and reduce_year_vocab_size:\n",
    "            w1 = w[0:2]\n",
    "            w2 = w[2:4]\n",
    "            voiced_vocab.add(w1)\n",
    "            voiced_vocab.add(w2)\n",
    "        else:\n",
    "            voiced_vocab.add(w)\n",
    "voiced_vocab.remove(\"\")\n",
    "\n",
    "print('Silent Vocab Size, Voiced Vocab Size:', len(silent_vocab), len(voiced_vocab))\n",
    "\n",
    "silent_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed38e41-90b1-403e-9eba-51aea9a3c7d6",
   "metadata": {},
   "source": [
    "I'm not sure how the authors calculated the 67 words in their vocab, as there are actually 113 unique words within the dataset. The way they calculate their vocabulary must be different to how I have. The method I have used is to sum 12 hour suffixes (AM/PM) with 1 digit number occurances, two digit number occurances, 7 days a week and 12 months a year.\n",
    "\n",
    "The authors must be reducing the vocabulary down by grouping some of the numbers which are uttered, further investigation here is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbdc742-56fc-45c0-8e51-4d845578a3d4",
   "metadata": {},
   "source": [
    "#### Utterance Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ce9ae2-5eea-4d3e-816c-7b66ce12d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_silent_utters = [info[\"text\"] for info in silent_info]\n",
    "raw_silent_utters = list(filter(lambda x: x != \"\", raw_silent_utters))\n",
    "\n",
    "raw_voiced_utters = [info[\"text\"] for info in voiced_info]\n",
    "raw_voiced_utters = list(filter(lambda x: x != \"\", raw_voiced_utters))\n",
    "\n",
    "silent_utterances = set(raw_silent_utters)\n",
    "voiced_utterances = set(raw_voiced_utters)\n",
    "\n",
    "silent_utterance_indices = set([info[\"sentence_index\"] for info in silent_info])\n",
    "voiced_utterance_indices = set([info[\"sentence_index\"] for info in voiced_info])\n",
    "\n",
    "def get_utter_word_count(utterance):\n",
    "    words = re.split(\":| \", utterance)\n",
    "    cnt = 0\n",
    "    for w in words:\n",
    "        if len(w) == 4 and w.isnumeric():\n",
    "            cnt += 2\n",
    "        else:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "avg_silent_utter_words = [get_utter_word_count(u) for u in raw_silent_utters]\n",
    "print('Silent utter avg:', set(avg_silent_utter_words), avg_silent_utter_words, sum(avg_silent_utter_words), len(avg_silent_utter_words), sum(avg_silent_utter_words) / len(avg_silent_utter_words))\n",
    "avg_silent_utter_words = sum(avg_silent_utter_words) / len(avg_silent_utter_words)\n",
    "\n",
    "avg_voiced_utter_words = [get_utter_word_count(u) for u in raw_voiced_utters]\n",
    "print('Voiced utter avg:', set(avg_voiced_utter_words), avg_voiced_utter_words, sum(avg_voiced_utter_words), len(avg_voiced_utter_words), sum(avg_voiced_utter_words) / len(avg_voiced_utter_words))\n",
    "avg_voiced_utter_words = sum(avg_voiced_utter_words) / len(avg_voiced_utter_words)\n",
    "\n",
    "print('Silent, Voiced utterance counts:', len(silent_utterances), len(voiced_utterances))\n",
    "print('Index counts (silent, voiced):', len(silent_utterance_indices), len(voiced_utterance_indices))\n",
    "print('Raw (silent, voiced) utterance counts:', len(raw_silent_utters), len(raw_voiced_utters))\n",
    "print('Avg words/utterance (silent, voiced) counts:', avg_silent_utter_words, avg_voiced_utter_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f35e8-b3f9-4046-84a3-5f9768a1c120",
   "metadata": {},
   "source": [
    "The sentence index (in other words, the indices into the utterances) matches what is reported exactly.\n",
    "The [Digital Voicing of Silent Speech](https://arxiv.org/pdf/2010.02960.pdf) paper reports\n",
    "500 utterances, and their are 500 sentences (i.e. utterances) plus an additional recording which\n",
    "contains no speech.\n",
    "Presumably this is an initial recording to ensure the recording environment (OpenBCI\n",
    "EEG recording hardware and software) were working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba2fa9-dc60-4ee0-8d52-55175078cec6",
   "metadata": {},
   "source": [
    "#### Audio Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1b7028a8-005f-4b82-9583-9ca5ee0649c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio (Silent, Voiced) duration (mins): 26.46, 29.53\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\"\"\"\n",
    "silent_dir\n",
    "voiced_dir\n",
    "\"\"\"\n",
    "\n",
    "import librosa\n",
    "silent_flacs = list(filter(lambda x: x.endswith(\"clean.flac\"), os.listdir(silent_dir)))\n",
    "voiced_flacs = list(filter(lambda x: x.endswith(\"clean.flac\"), os.listdir(voiced_dir)))\n",
    "\n",
    "silent_audio_duration = 0 # Seconds\n",
    "for fname in silent_flacs:\n",
    "    silent_audio_duration += librosa.get_duration(filename=os.path.join(silent_dir, fname))\n",
    "    \n",
    "voiced_audio_duration = 0 # Seconds\n",
    "for fname in voiced_flacs:\n",
    "    voiced_audio_duration += librosa.get_duration(filename=os.path.join(voiced_dir, fname))\n",
    "    \n",
    "silent_mins = silent_audio_duration / 60.0\n",
    "audio_mins = voiced_audio_duration / 60.0\n",
    "\n",
    "print(f'Audio (Silent, Voiced) duration (mins): {silent_mins:.2f}, {audio_mins:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
